{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahug/ds-tensorflow-colab/blob/master/Tensorflow%20-%20Bank%20Customer%20Satisfaction%20Using%20CNN%20and%20Feature%20Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0-W6MdWw5qr"
      },
      "source": [
        "**Tensorflow - Bank Customer Satisfaction Using CNN and Feature Selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjN6c7XQsops"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-gpu==2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7KY6oB7tGO2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2bXZYWp1r3f"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlCTLO3F1v85"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4DjGyP614Ws"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ncvlCZw2I4N"
      },
      "outputs": [],
      "source": [
        "# Dataset Link - https://github.com/laxmimerit/Data-Files-for-Feature-Selection\n",
        "!git clone https://github.com/laxmimerit/Data-Files-for-Feature-Selection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62tG-3Ya2tiQ"
      },
      "outputs": [],
      "source": [
        "# Read Data\n",
        "data = pd.read_csv(\"/content/Data-Files-for-Feature-Selection/santander-train.csv\")\n",
        "data.head()\n",
        "\n",
        "# target is 0 - Unsattisfied and 1 Satisfied in below data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MZd5VQA3AWa"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMeFLnq_3X9u"
      },
      "outputs": [],
      "source": [
        "x = data.drop(labels=[\"ID\", \"TARGET\"], axis=1) # Dropping unnecessary data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xytzckq3ttK"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTj2mgCE3yUr"
      },
      "outputs": [],
      "source": [
        "y = data[\"TARGET\"] # This is waht we are predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f0WXljt3588"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxhQ4Ejn4JpT"
      },
      "outputs": [],
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIQ81T9y4Ql8"
      },
      "source": [
        "#### **Remove Constant, Quassi Constant and Duplicate Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdzBekcU4XeS"
      },
      "outputs": [],
      "source": [
        "filter = VarianceThreshold(0.01) # Removing 1%\n",
        "x_train = filter.fit_transform(x_train)\n",
        "x_test = filter.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuUsf8mX5L-E"
      },
      "outputs": [],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLl5ZM9o5SNk"
      },
      "outputs": [],
      "source": [
        "# Removing Duplicates.\n",
        "# Transpossing Rows and Columns\n",
        "x_train_t = x_train.T\n",
        "x_test_t = x_test.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er0HJcMB5q4n"
      },
      "outputs": [],
      "source": [
        "x_train_t = pd.DataFrame(x_train_t)\n",
        "x_test_t = pd.DataFrame(x_test_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpBhjHax5zJp"
      },
      "outputs": [],
      "source": [
        "# Here we can see we have transformed rows into columns and columns into rows\n",
        "x_train_t.shape, x_test_t.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9FVE73p6DZq"
      },
      "outputs": [],
      "source": [
        "x_train_t.duplicated().sum() # Finiding No of Duplicated Features that needs to be removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kfiLIsp6Suk"
      },
      "outputs": [],
      "source": [
        "duplicated_features = x_train_t.duplicated()\n",
        "duplicated_features\n",
        "\n",
        "#True gives duplicated features and False non duplicated features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ8j4Bsf6kf0"
      },
      "outputs": [],
      "source": [
        "# Now we only want to keep non duplicated features.\n",
        "# Inverting True to False and False to True\n",
        "features_to_keep = [not index for index in duplicated_features]\n",
        "features_to_keep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOY-U2EK6_F9"
      },
      "outputs": [],
      "source": [
        "# Filtering and Transpossing back to original form\n",
        "x_train = x_train_t[features_to_keep].T\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "177beDPf7SaQ"
      },
      "outputs": [],
      "source": [
        "x_test = x_test_t[features_to_keep].T\n",
        "x_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7jcRCIw7iNS"
      },
      "source": [
        "**Standardizing data**. Bringing variance to common level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YVM_qRC75ym"
      },
      "outputs": [],
      "source": [
        "x_train, x_test # Here we can see lot of zeroes and hig differences in values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l47qp5O7giA"
      },
      "outputs": [],
      "source": [
        "# Bringing down the differences.\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_90c6lv58KaW"
      },
      "outputs": [],
      "source": [
        "x_train, x_test # Now we can see the differences are close enough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2cBfXQj8Um2"
      },
      "outputs": [],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLSIHyx28dhG"
      },
      "outputs": [],
      "source": [
        "# Reshapping the 2D data to 3D as neural networks understand 3D\n",
        "x_train = x_train.reshape(60816, 256, 1)\n",
        "x_test = x_test.reshape(15204, 256, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL669cK38w66"
      },
      "outputs": [],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x779kQiZ80l3"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2XniZbT9Ckd"
      },
      "source": [
        "**Build CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHMYmwmN9B4P"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation=\"relu\", input_shape=(256, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(2))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool1D(2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHuCfr6c-cil"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NsXFUsI-mps"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(lr=0.00005), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuRQLo0P_GUV"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OFWnftNF-ym"
      },
      "outputs": [],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieQIQ_AYGDo6"
      },
      "outputs": [],
      "source": [
        "epoch_range = range(1, 11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2n0FZjkGJmH"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation accuracy values\n",
        "# sparse_categorical_accuracy vs val_sparse_categorical_accuracy\n",
        "plt.plot(epoch_range, history.history[\"accuracy\"])\n",
        "plt.plot(epoch_range, history.history[\"val_accuracy\"])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE5C_zyUGNMX"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss values\n",
        "# Loss vs Val_Loss\n",
        "plt.plot(epoch_range, history.history[\"loss\"])\n",
        "plt.plot(epoch_range, history.history[\"val_loss\"])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Tensorflow - Bank Customer Satisfaction Using CNN and Feature Selection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
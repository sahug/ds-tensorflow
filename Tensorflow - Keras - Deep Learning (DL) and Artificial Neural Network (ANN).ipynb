{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahug/ds-tensorflow-colab/blob/master/Tensorflow%20-%20Keras%20-%20Deep%20Learning%20(DL)%20and%20Artificial%20Neural%20Network%20(ANN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensorflow - Keras - Deep Learning (DL) and Artificial Neural Network (ANN)**"
      ],
      "metadata": {
        "id": "SmZHW6O6-zDb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTzUTtvp-tzv"
      },
      "source": [
        "**Steps for building ANN (Aritificial Neural Network)**\n",
        "- Data Preprocessing (Reading or preparing the data)\n",
        "- Add input layer\n",
        "- Random weight initializer\n",
        "- Add hidden layers\n",
        "- Select Optimizer, Loss and Performance Metrices (Accuracy, F1_Score, etc)\n",
        "- Compile the model\n",
        "- Use model.fit to train the model\n",
        "- Evaluate the model\n",
        "- Adjust optimization parameters or model if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjVM49uT-tzz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential  # Importing sequential model\n",
        "from tensorflow.keras.layers import Dense, Flatten  # Importing layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVx1HzMc-tz0"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNAJeeQL-tz0"
      },
      "source": [
        "**Data Preprocessing (Reading or preparing the data)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDBh_Bke-tz1"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"data/customer_churn_modelling.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLjj1btm-tz1"
      },
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6QOiDit-tz1"
      },
      "source": [
        "Dropping unrelated column that doesn't give much information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgwVjB3i-tz2"
      },
      "outputs": [],
      "source": [
        "# X is given variables agains which the prediction will be made\n",
        "X = dataset.drop(labels=[\"RowNumber\", \"CustomerId\", \"Surname\", \"Exited\"], axis=1)\n",
        "\n",
        "# Y is the outcome\n",
        "Y = dataset[\"Exited\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiTIUBiZ-tz3"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK27UUDR-tz3"
      },
      "outputs": [],
      "source": [
        "Y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqfaMHh7-tz4"
      },
      "source": [
        "Since AAN waorks with numerical data. Converting strings to numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOB0H-Ki-tz4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQxTkGWq-tz4"
      },
      "outputs": [],
      "source": [
        "# Converting Geography\n",
        "\n",
        "geography_encoder = LabelEncoder()\n",
        "X[\"Geography\"] = geography_encoder.fit_transform(X[\"Geography\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AABGQrul-tz5"
      },
      "outputs": [],
      "source": [
        "# Now we can see Geography is converted to numbers\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geeotf9e-tz5"
      },
      "outputs": [],
      "source": [
        "# Now converting Gender\n",
        "\n",
        "gender_encoder = LabelEncoder()\n",
        "X[\"Gender\"] = gender_encoder.fit_transform(X[\"Gender\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdeLiS3d-tz6"
      },
      "outputs": [],
      "source": [
        "# Now we can see Gender is converted to numbers\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xva_9aqr-tz7"
      },
      "outputs": [],
      "source": [
        "# Convert categorical variable into dummy/indicator variables.\n",
        "\n",
        "X = pd.get_dummies(X, drop_first=True, columns=[\"Geography\"])\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMDMEpRy-tz7"
      },
      "source": [
        "**Feature Standardization**\n",
        "\n",
        "- Feature Standardization is used to bring down the variance in each feature, columns, closer. As our dataset has the column with values varying with each other in a large scale. We will standardize each column so the diffrence in the values in each columns are not too high. Target is to achieve a mean of 0 for each columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfUfd4B8-tz7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IoonBkH-tz8"
      },
      "outputs": [],
      "source": [
        "# Splitting dataset into training and testing set\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=0, stratify=Y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn7hygIw-tz8"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-q9Xv-d-tz9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BjA7rVd-tz9"
      },
      "source": [
        "**Build ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfj3MzQP-tz9"
      },
      "source": [
        "Add input layer, Random weight initializer, Add hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wffCLSjX-tz9"
      },
      "outputs": [],
      "source": [
        "X.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPn1pFNN-tz9"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Input Layer. Input all data or all columns in original data.\n",
        "# X.shape[1] will give us the count of column in 1st row.\n",
        "model.add(Dense(X.shape[1], activation=\"relu\", input_dim=X.shape[1]))  # X.shape[1] = 11\n",
        "\n",
        "# Hidden layer. Repeat the test for 128 times.\n",
        "model.add(Dense(128, activation=\"relu\"))  # 128 No of layers. (11 + 1) x 128 = 1536\n",
        "\n",
        "# Output Layer. Ouput no of layers is expected different outcome -1. Here it is, exited or not exited, 2 - 1 = 1\n",
        "model.add(Dense(1, activation=\"sigmoid\"))  # (128 + 1) x 1 = 129\n",
        "\n",
        "# Total\n",
        "# 1536 + 129 = 1797"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9qH6F9pj-tz-"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZctVKkK--tz-"
      },
      "outputs": [],
      "source": [
        "X.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTHriBND-tz-"
      },
      "source": [
        "Select Optimizer, Loss and Performance Metrices (Accuracy, F1_Score, etc) and Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2cNxBpg-tz-"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjf-RK3j-tz-"
      },
      "source": [
        "Use **model.fit** to train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im1op_j9-tz-"
      },
      "outputs": [],
      "source": [
        "# batch_size - Represents when to update the weight. For value = 1 it will update the weight for each inputs.\n",
        "# epoch - Represents how many times it will loop.\n",
        "# verbose - Gives to progress bar of how training is going.\n",
        "model.fit(X_train, Y_train.to_numpy(), batch_size=10, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21jvduLF-tz_"
      },
      "outputs": [],
      "source": [
        "# Predicting Y value on our test data\n",
        "\n",
        "Y_pred = model.predict_classes(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux3VQD_u-tz_"
      },
      "source": [
        "We can see the Y_pred matches the Y_test. So it means our model is predicting correctly. Look at 2nd last value. Its 1 for both Y_pred and Y_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdbcqArm-tz_"
      },
      "outputs": [],
      "source": [
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJz5aBtI-tz_"
      },
      "outputs": [],
      "source": [
        "Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhiobPWa-tz_"
      },
      "source": [
        "**Evaluate the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUxGBCFC-t0A"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, Y_test.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV04RRMX-t0A"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6e_OZy6-t0A"
      },
      "outputs": [],
      "source": [
        "confusion_matrix(Y_test, Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2hoUnA9-t0A"
      },
      "outputs": [],
      "source": [
        "accuracy_score(Y_test, Y_pred)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Tensorflow - Keras - Deep Learning (DL) and Artificial Neural Network (ANN).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
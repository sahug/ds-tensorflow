{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahug/ds-tensorflow-colab/blob/master/Tensorflow%20-%20Basic%20Image%20Classification%20MNIST%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensorflow - Basic Image Classification MNIST Dataset**"
      ],
      "metadata": {
        "id": "5hQjtUPel1pS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GA4e-zsilwq9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BBbQqPH8lwq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc51a43-ee5b-4a0f-c974-1ba53beffd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e8fBDpyclwq_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ONq8chImlwq_"
      },
      "outputs": [],
      "source": [
        "mnist = keras.datasets.fashion_mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUsFLr3OlwrA"
      },
      "source": [
        "**Load the data.**\n",
        "\n",
        "Load and split dataset in test and training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8Q_Zq6lnlwrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5af595f-d55b-455f-f88c-2a4bf1d45c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eX8f8yEilwrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f599845-2604-4ac2-bcef-81472b79fb8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AoelA-YDlwrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b517b06-aec3-47fe-c34e-67d7f78c2bd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(255, 0, 72.94035223214286)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "np.max(X_train), np.min(X_train), np.mean(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HXjNvzP2lwrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe728944-f3d6-4e8c-ec70-cad58f548c99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(255, 0, 73.14656658163265)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.max(X_test), np.min(X_test), np.mean(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbETlSVXlwrC"
      },
      "source": [
        "**Defining MNIST dataset category.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "v7LUhR7hlwrD"
      },
      "outputs": [],
      "source": [
        "class_names = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTh1YVB5lwrD"
      },
      "source": [
        "**Data Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BbL1VzIWlwrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6aa25597-ec0f-44f1-818f-fdb5365eeb0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fbaf4d12650>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.imshow(X_train[0])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CJD0ji5KlwrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e42d00f8-6bcc-4722-e6d5-133f06ccd800"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fbaf475aa50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.imshow(X_train[1])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3tf9RQelwrF"
      },
      "source": [
        "Since the Neural Network takes values between 0 and 1. We need to bring or training data between 0 and 1. To do that we will divide all our training and test data by the max value of the training/test as found above \"np.max(X_train)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ml-t5FailwrF"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / np.max(X_train)  # 255 is the max value of the training data. nm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3oxi3t0rlwrF"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / np.max(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z12RldLzlwrF"
      },
      "source": [
        "Now we can see below that we have brought our data between 0 and 1. Look at the bar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V_LYgj78lwrG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "e403c61b-f005-4e9d-9513-cca395cd7156"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fbaf46a6310>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.imshow(X_train[0])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GsI4FRHmlwrG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "0f9b125d-f1a7-4498-890a-df5d7d99c435"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fbaf45e1650>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.imshow(X_train[1])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1pgLZhTlwrG"
      },
      "source": [
        "**Build the model with Tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-h7y93ZGlwrG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6IRBqyZlwrH"
      },
      "source": [
        "**Sequential Model**\n",
        "\n",
        "The most common type of model is the Sequential model, which is a linear stack of layers. You can create a Sequential model by passing a list of layers to the sequential() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jD3E4bmwlwrH"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Flatten just converts the data into a single dimension. 28 x 28 is what we have in out training data.\n",
        "# As you can see above. It will convert 28 x 28 in to a single dimension, which is 784\n",
        "\n",
        "# Input Layer. Input all data.\n",
        "model.add(Flatten(input_shape=(28, 28)))  # 28 x 28 = 784\n",
        "\n",
        "# Hidden layer.\n",
        "model.add(\n",
        "    Dense(128, activation=\"relu\")\n",
        ")  # 128 is no of layers. (784 + 1) x 128 = 100480\n",
        "\n",
        "# Output Layer. Ouput no of layers is expected different outcome -1. Here it is 11 - 1 = 10\n",
        "model.add(Dense(10, activation=\"softmax\"))  # (128 + 1) x 10 = 1290.\n",
        "\n",
        "# Total\n",
        "# 100480 + 1290 = 101770"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BkEjT1jxlwrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5459302e-c82e-4c7a-cad3-5bb32e6ecc66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH33ZHqxlwrI"
      },
      "source": [
        "**Compile Model**\n",
        "\n",
        "Few important things for compiling the model:\n",
        "1) Define Loss Function - Minimizes the error during the training\n",
        "\n",
        "2) Optimizer - Optimizes the model\n",
        "\n",
        "3) Metrices - Generate information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-h_zqBLKlwrI"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cncDT3QZlwrI"
      },
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SkTijr4YlwrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b743f479-74c2-44a1-ac59-ad3216a7e5e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.4970 - accuracy: 0.8214 - val_loss: 0.3944 - val_accuracy: 0.8602\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 12s 3ms/step - loss: 0.3764 - accuracy: 0.8607 - val_loss: 0.3655 - val_accuracy: 0.8686\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 13s 3ms/step - loss: 0.3387 - accuracy: 0.8762 - val_loss: 0.3587 - val_accuracy: 0.8688\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.3168 - accuracy: 0.8832 - val_loss: 0.3511 - val_accuracy: 0.8777\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 13s 3ms/step - loss: 0.2976 - accuracy: 0.8908 - val_loss: 0.3320 - val_accuracy: 0.8790\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 13s 3ms/step - loss: 0.2837 - accuracy: 0.8945 - val_loss: 0.3469 - val_accuracy: 0.8766\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 13s 3ms/step - loss: 0.2683 - accuracy: 0.8995 - val_loss: 0.3440 - val_accuracy: 0.8802\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.2602 - accuracy: 0.9033 - val_loss: 0.3253 - val_accuracy: 0.8836\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.2486 - accuracy: 0.9051 - val_loss: 0.3301 - val_accuracy: 0.8838\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 12s 2ms/step - loss: 0.2416 - accuracy: 0.9094 - val_loss: 0.3291 - val_accuracy: 0.8858\n"
          ]
        }
      ],
      "source": [
        "# epoch - No of times it will train the dataset on this model.\n",
        "# validation_split - Only given percent will be used for validation accuracy and validation loss.\n",
        "history = model.fit(X_train, Y_train, epochs=10, batch_size=10, validation_split=0.2)\n",
        "\n",
        "# history is used below to plot learning curve and confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZamPI8IlwrI"
      },
      "source": [
        "**Evaluate the accuracy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9MDaTTllwrI"
      },
      "source": [
        "Here we will see that the accuracy of the model during training was 0.9109, above, but it was less during the testing, below. This shows the overfitting of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9JASpeu0lwrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbfc7da-8a42-465e-ea0c-6c05186c7914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 77.9136 - accuracy: 0.8511\n",
            "77.91361236572266\n",
            "0.8511000275611877\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test)\n",
        "print(test_loss)\n",
        "print(test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IkJItjGwlwrJ"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-JOK-XlYlwrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc49f53-46cf-44dd-cfc6-203958f79e3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "G199SUtrlwrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68efb107-e103-4d9d-dbe0-50d56777eb50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7izQMhq_lwrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719d8308-9c33-40f1-bed1-4685e44a3278"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "np.argmax(pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XRbu8vXvlwrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11bce19b-7652-4b6e-804b-d80c8b471056"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "np.argmax(pred[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rtPyMU0lwrK"
      },
      "source": [
        "**Plotting Learning Curve**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9HtvWh2lwrK"
      },
      "source": [
        "Install mlxtend using \n",
        "- conda install --name tensorflow20 -c conda-forge mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Q5ah6U0tlwrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd2480c-3131-4ac4-aabc-a184f8f8e444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on Sequential in module keras.engine.sequential object:\n",
            "\n",
            "class Sequential(keras.engine.functional.Functional)\n",
            " |  Sequential(*args, **kwargs)\n",
            " |  \n",
            " |  `Sequential` groups a linear stack of layers into a `tf.keras.Model`.\n",
            " |  \n",
            " |  `Sequential` provides training and inference features on this model.\n",
            " |  \n",
            " |  Examples:\n",
            " |  \n",
            " |  ```python\n",
            " |  # Optionally, the first layer can receive an `input_shape` argument:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
            " |  # Afterwards, we do automatic shape inference:\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  \n",
            " |  # This is identical to the following:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.Input(shape=(16,)))\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  \n",
            " |  # Note that you can also omit the `input_shape` argument.\n",
            " |  # In that case the model doesn't have any weights until the first call\n",
            " |  # to a training/evaluation method (since it isn't yet built):\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  # model.weights not created yet\n",
            " |  \n",
            " |  # Whereas if you specify the input shape, the model gets built\n",
            " |  # continuously as you are adding layers:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  len(model.weights)\n",
            " |  # Returns \"4\"\n",
            " |  \n",
            " |  # When using the delayed-build pattern (no input shape specified), you can\n",
            " |  # choose to manually build your model by calling\n",
            " |  # `build(batch_input_shape)`:\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(4))\n",
            " |  model.build((None, 16))\n",
            " |  len(model.weights)\n",
            " |  # Returns \"4\"\n",
            " |  \n",
            " |  # Note that when using the delayed-build pattern (no input shape specified),\n",
            " |  # the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
            " |  # or the first time you call the model on some input data.\n",
            " |  model = tf.keras.Sequential()\n",
            " |  model.add(tf.keras.layers.Dense(8))\n",
            " |  model.add(tf.keras.layers.Dense(1))\n",
            " |  model.compile(optimizer='sgd', loss='mse')\n",
            " |  # This builds the model for the first time:\n",
            " |  model.fit(x, y, batch_size=32, epochs=10)\n",
            " |  ```\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Sequential\n",
            " |      keras.engine.functional.Functional\n",
            " |      keras.engine.training.Model\n",
            " |      keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.training.tracking.autotrackable.AutoTrackable\n",
            " |      tensorflow.python.training.tracking.base.Trackable\n",
            " |      keras.utils.version_utils.LayerVersionSelector\n",
            " |      keras.utils.version_utils.ModelVersionSelector\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, layers=None, name=None)\n",
            " |      Creates a `Sequential` model instance.\n",
            " |      \n",
            " |      Args:\n",
            " |        layers: Optional list of layers to add to the model.\n",
            " |        name: Optional name for the model.\n",
            " |  \n",
            " |  add(self, layer)\n",
            " |      Adds a layer instance on top of the layer stack.\n",
            " |      \n",
            " |      Args:\n",
            " |          layer: layer instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          TypeError: If `layer` is not a layer instance.\n",
            " |          ValueError: In case the `layer` argument does not\n",
            " |              know its input shape.\n",
            " |          ValueError: In case the `layer` argument has\n",
            " |              multiple output tensors, or is already connected\n",
            " |              somewhere else (forbidden in `Sequential` models).\n",
            " |  \n",
            " |  build(self, input_shape=None)\n",
            " |      Builds the model based on input shapes received.\n",
            " |      \n",
            " |      This is to be used for subclassed models, which do not know at instantiation\n",
            " |      time what their inputs look like.\n",
            " |      \n",
            " |      This method only exists for users who want to call `model.build()` in a\n",
            " |      standalone way (as a substitute for calling the model on real data to\n",
            " |      build it). It will never be called by the framework (and thus it will\n",
            " |      never throw unexpected errors in an unrelated workflow).\n",
            " |      \n",
            " |      Args:\n",
            " |       input_shape: Single tuple, `TensorShape` instance, or list/dict of shapes,\n",
            " |         where shapes are tuples, integers, or `TensorShape` instances.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError:\n",
            " |          1. In case of invalid user-provided data (not of type tuple,\n",
            " |             list, `TensorShape`, or dict).\n",
            " |          2. If the model requires call arguments that are agnostic\n",
            " |             to the input shapes (positional or keyword arg in call signature).\n",
            " |          3. If not all layers were properly built.\n",
            " |          4. If float type inputs are not supported within the layers.\n",
            " |      \n",
            " |        In each of these cases, the user should build their model by calling it\n",
            " |        on real tensor data.\n",
            " |  \n",
            " |  call(self, inputs, training=None, mask=None)\n",
            " |      Calls the model on new inputs.\n",
            " |      \n",
            " |      In this case `call` just reapplies\n",
            " |      all ops in the graph to the new inputs\n",
            " |      (e.g. build a new computational graph from the provided inputs).\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: A tensor or list of tensors.\n",
            " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
            " |            the `Network` in training mode or inference mode.\n",
            " |          mask: A mask or list of masks. A mask can be\n",
            " |              either a tensor or None (no mask).\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor if there is a single output, or\n",
            " |          a list of tensors if there are more than one outputs.\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      This method will cause the layer's state to be built, if that has not\n",
            " |      happened before. This requires that the layer will later be used with\n",
            " |      inputs that match the input shape provided here.\n",
            " |      \n",
            " |      Args:\n",
            " |          input_shape: Shape tuple (tuple of integers)\n",
            " |              or list of shape tuples (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An input shape tuple.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the layer.\n",
            " |      \n",
            " |      A layer config is a Python dictionary (serializable)\n",
            " |      containing the configuration of a layer.\n",
            " |      The same layer can be reinstantiated later\n",
            " |      (without its trained weights) from this configuration.\n",
            " |      \n",
            " |      The config of a layer does not include connectivity\n",
            " |      information, nor the layer class name. These are handled\n",
            " |      by `Network` (one layer of abstraction above).\n",
            " |      \n",
            " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
            " |      every time it is called. The callers should make a copy of the returned dict\n",
            " |      if they want to modify it.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary.\n",
            " |  \n",
            " |  pop(self)\n",
            " |      Removes the last layer in the model.\n",
            " |      \n",
            " |      Raises:\n",
            " |          TypeError: if there are no layers in the model.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  from_config(config, custom_objects=None) from builtins.type\n",
            " |      Instantiates a Model from its config (output of `get_config()`).\n",
            " |      \n",
            " |      Args:\n",
            " |          config: Model config dictionary.\n",
            " |          custom_objects: Optional dictionary mapping names\n",
            " |              (strings) to custom classes or functions to be\n",
            " |              considered during deserialization.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A model instance.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: In case of improperly formatted config dict.\n",
            " |          TypeError: In case the config does match the cls constructor.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  input_spec\n",
            " |      `InputSpec` instance(s) describing the input format for this layer.\n",
            " |      \n",
            " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
            " |      the layer to run input compatibility checks when it is called.\n",
            " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
            " |      of rank 4. As such, you can set, in `__init__()`:\n",
            " |      \n",
            " |      ```python\n",
            " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            " |      ```\n",
            " |      \n",
            " |      Now, if you try to call the layer on an input that isn't rank 4\n",
            " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
            " |      error:\n",
            " |      \n",
            " |      ```\n",
            " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            " |      ```\n",
            " |      \n",
            " |      Input checks that can be specified via `input_spec` include:\n",
            " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            " |      - Shape\n",
            " |      - Rank (ndim)\n",
            " |      - Dtype\n",
            " |      \n",
            " |      For more information, see `tf.keras.layers.InputSpec`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            " |  \n",
            " |  layers\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.functional.Functional:\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  __copy__(self)\n",
            " |  \n",
            " |  __deepcopy__(self, memo)\n",
            " |  \n",
            " |  __reduce__(self)\n",
            " |      Helper for pickle.\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, **kwargs)\n",
            " |      Configures the model for training.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
            " |                    loss=tf.keras.losses.BinaryCrossentropy(),\n",
            " |                    metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
            " |                             tf.keras.metrics.FalseNegatives()])\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
            " |            `tf.keras.optimizers`.\n",
            " |          loss: Loss function. Maybe be a string (name of loss function), or\n",
            " |            a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
            " |            function is any callable with the signature `loss = fn(y_true,\n",
            " |            y_pred)`, where `y_true` are the ground truth values, and\n",
            " |            `y_pred` are the model's predictions.\n",
            " |            `y_true` should have shape\n",
            " |            `(batch_size, d0, .. dN)` (except in the case of\n",
            " |            sparse loss functions such as\n",
            " |            sparse categorical crossentropy which expects integer arrays of shape\n",
            " |            `(batch_size, d0, .. dN-1)`).\n",
            " |            `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
            " |            The loss function should return a float tensor.\n",
            " |            If a custom `Loss` instance is\n",
            " |            used and reduction is set to `None`, return value has shape\n",
            " |            `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
            " |            values; otherwise, it is a scalar. If the model has multiple outputs,\n",
            " |            you can use a different loss on each output by passing a dictionary\n",
            " |            or a list of losses. The loss value that will be minimized by the\n",
            " |            model will then be the sum of all individual losses, unless\n",
            " |            `loss_weights` is specified.\n",
            " |          metrics: List of metrics to be evaluated by the model during training\n",
            " |            and testing. Each of this can be a string (name of a built-in\n",
            " |            function), function or a `tf.keras.metrics.Metric` instance. See\n",
            " |            `tf.keras.metrics`. Typically you will use `metrics=['accuracy']`. A\n",
            " |            function is any callable with the signature `result = fn(y_true,\n",
            " |            y_pred)`. To specify different metrics for different outputs of a\n",
            " |            multi-output model, you could also pass a dictionary, such as\n",
            " |            `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
            " |            You can also pass a list to specify a metric or a list of metrics\n",
            " |            for each output, such as `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
            " |            or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass the\n",
            " |            strings 'accuracy' or 'acc', we convert this to one of\n",
            " |            `tf.keras.metrics.BinaryAccuracy`,\n",
            " |            `tf.keras.metrics.CategoricalAccuracy`,\n",
            " |            `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss\n",
            " |            function used and the model output shape. We do a similar\n",
            " |            conversion for the strings 'crossentropy' and 'ce' as well.\n",
            " |          loss_weights: Optional list or dictionary specifying scalar coefficients\n",
            " |            (Python floats) to weight the loss contributions of different model\n",
            " |            outputs. The loss value that will be minimized by the model will then\n",
            " |            be the *weighted sum* of all individual losses, weighted by the\n",
            " |            `loss_weights` coefficients.\n",
            " |              If a list, it is expected to have a 1:1 mapping to the model's\n",
            " |                outputs. If a dict, it is expected to map output names (strings)\n",
            " |                to scalar coefficients.\n",
            " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
            " |            `sample_weight` or `class_weight` during training and testing.\n",
            " |          run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s\n",
            " |            logic will not be wrapped in a `tf.function`. Recommended to leave\n",
            " |            this as `None` unless your `Model` cannot be run inside a\n",
            " |            `tf.function`. `run_eagerly=True` is not supported when using\n",
            " |            `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          steps_per_execution: Int. Defaults to 1. The number of batches to run\n",
            " |            during each `tf.function` call. Running multiple batches inside a\n",
            " |            single `tf.function` call can greatly improve performance on TPUs or\n",
            " |            small models with a large Python overhead. At most, one full epoch\n",
            " |            will be run each execution. If a number larger than the size of the\n",
            " |            epoch is passed, the execution will be truncated to the size of the\n",
            " |            epoch. Note that if `steps_per_execution` is set to `N`,\n",
            " |            `Callback.on_batch_begin` and `Callback.on_batch_end` methods will\n",
            " |            only be called every `N` batches (i.e. before/after each `tf.function`\n",
            " |            execution).\n",
            " |          jit_compile: If `True`, compile the model training step with XLA.\n",
            " |            [XLA](https://www.tensorflow.org/xla) is an optimizing compiler for\n",
            " |            machine learning.\n",
            " |            `jit_compile` is not enabled for by default.\n",
            " |            This option cannot be enabled with `run_eagerly=True`.\n",
            " |            Note that `jit_compile=True` is\n",
            " |            may not necessarily work for all models.\n",
            " |            For more information on supported operations please refer to the\n",
            " |            [XLA documentation](https://www.tensorflow.org/xla).\n",
            " |            Also refer to\n",
            " |            [known XLA issues](https://www.tensorflow.org/xla/known_issues) for\n",
            " |            more details.\n",
            " |          **kwargs: Arguments supported for backwards compatibility only.\n",
            " |  \n",
            " |  compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None)\n",
            " |      Compute the total loss, validate it, and return it.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom loss\n",
            " |      computation logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Model):\n",
            " |      \n",
            " |        def __init__(self, *args, **kwargs):\n",
            " |          super(MyModel, self).__init__(*args, **kwargs)\n",
            " |          self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
            " |      \n",
            " |        def compute_loss(self, x, y, y_pred, sample_weight):\n",
            " |          loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))\n",
            " |          loss += tf.add_n(self.losses)\n",
            " |          self.loss_tracker.update_state(loss)\n",
            " |          return loss\n",
            " |      \n",
            " |        def reset_metrics(self):\n",
            " |          self.loss_tracker.reset_states()\n",
            " |      \n",
            " |        @property\n",
            " |        def metrics(self):\n",
            " |          return [self.loss_tracker]\n",
            " |      \n",
            " |      tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))\n",
            " |      dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)\n",
            " |      \n",
            " |      inputs = tf.keras.layers.Input(shape=(10,), name='my_input')\n",
            " |      outputs = tf.keras.layers.Dense(10)(inputs)\n",
            " |      model = MyModel(inputs, outputs)\n",
            " |      model.add_loss(tf.reduce_sum(outputs))\n",
            " |      \n",
            " |      optimizer = tf.keras.optimizers.SGD()\n",
            " |      model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
            " |      model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
            " |      print('My custom loss: ', model.loss_tracker.result().numpy())\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The total loss as a `tf.Tensor`, or `None` if no loss results (which is\n",
            " |        the case when called by `Model.test_step`).\n",
            " |  \n",
            " |  compute_metrics(self, x, y, y_pred, sample_weight)\n",
            " |      Update metric states and collect all metrics to be returned.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom metric\n",
            " |      updating and collection logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      ```python\n",
            " |      class MyModel(tf.keras.Sequential):\n",
            " |      \n",
            " |        def compute_metrics(self, x, y, y_pred, sample_weight):\n",
            " |      \n",
            " |          # This super call updates `self.compiled_metrics` and returns results\n",
            " |          # for all metrics listed in `self.metrics`.\n",
            " |          metric_results = super(MyModel, self).compute_metrics(\n",
            " |              x, y, y_pred, sample_weight)\n",
            " |      \n",
            " |          # Note that `self.custom_metric` is not listed in `self.metrics`.\n",
            " |          self.custom_metric.update_state(x, y, y_pred, sample_weight)\n",
            " |          metric_results['custom_metric_name'] = self.custom_metric.result()\n",
            " |          return metric_results\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: Input data.\n",
            " |        y: Target data.\n",
            " |        y_pred: Predictions returned by the model (output of `model.call(x)`)\n",
            " |        sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end()`. Typically, the\n",
            " |        values of the metrics listed in `self.metrics` are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, return_dict=False, **kwargs)\n",
            " |      Returns the loss value & metrics values for the model in test mode.\n",
            " |      \n",
            " |      Computation is done in batches (see the `batch_size` arg.)\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            " |              or `(inputs, targets, sample_weights)`.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            " |            for iterator-like inputs` section of `Model.fit`.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
            " |            `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\n",
            " |            should not be specified (since targets will be obtained from the\n",
            " |            iterator/dataset).\n",
            " |          batch_size: Integer or `None`. Number of samples per batch of\n",
            " |            computation. If unspecified, `batch_size` will default to 32. Do not\n",
            " |            specify the `batch_size` if your data is in the form of a dataset,\n",
            " |            generators, or `keras.utils.Sequence` instances (since they generate\n",
            " |            batches).\n",
            " |          verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.\n",
            " |          sample_weight: Optional Numpy array of weights for the test samples,\n",
            " |            used for weighting the loss function. You can either pass a flat (1D)\n",
            " |            Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples), or in the case of\n",
            " |                temporal data, you can pass a 2D array with shape `(samples,\n",
            " |                sequence_length)`, to apply a different weight to every timestep\n",
            " |                of every sample. This argument is not supported when `x` is a\n",
            " |                dataset, instead pass sample weights as the third element of `x`.\n",
            " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            " |            before declaring the evaluation round finished. Ignored with the\n",
            " |            default value of `None`. If x is a `tf.data` dataset and `steps` is\n",
            " |            None, 'evaluate' will run until the dataset is exhausted. This\n",
            " |            argument is not supported with array inputs.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances. List of\n",
            " |            callbacks to apply during evaluation. See\n",
            " |            [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |            input only. Maximum size for the generator queue. If unspecified,\n",
            " |            `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |            only. Maximum number of processes to spin up when using process-based\n",
            " |            threading. If unspecified, `workers` will default to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |            `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |            threading. If unspecified, `use_multiprocessing` will default to\n",
            " |            `False`. Note that because this implementation relies on\n",
            " |            multiprocessing, you should not pass non-picklable arguments to the\n",
            " |            generator as they can't be passed easily to children processes.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |          **kwargs: Unused at this time.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Evaluates the model on a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.evaluate` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |            - A `tf.data` dataset. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
            " |              or `(inputs, targets, sample_weights)`.\n",
            " |            - A `tf.keras.utils.experimental.DatasetCreator`, which wraps a\n",
            " |              callable that takes a single argument of type\n",
            " |              `tf.distribute.InputContext`, and returns a `tf.data.Dataset`.\n",
            " |              `DatasetCreator` should be used when users prefer to specify the\n",
            " |              per-replica batching and sharding logic for the `Dataset`.\n",
            " |              See `tf.keras.utils.experimental.DatasetCreator` doc for more\n",
            " |              information.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given below. If using\n",
            " |            `tf.distribute.experimental.ParameterServerStrategy`, only\n",
            " |            `DatasetCreator` type is supported for `x`.\n",
            " |          y: Target data. Like the input data `x`,\n",
            " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
            " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
            " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
            " |            or `keras.utils.Sequence` instance, `y` should\n",
            " |            not be specified (since targets will be obtained from `x`).\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per gradient update.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          epochs: Integer. Number of epochs to train the model.\n",
            " |              An epoch is an iteration over the entire `x` and `y`\n",
            " |              data provided\n",
            " |              (unless the `steps_per_epoch` flag is set to\n",
            " |              something other than None).\n",
            " |              Note that in conjunction with `initial_epoch`,\n",
            " |              `epochs` is to be understood as \"final epoch\".\n",
            " |              The model is not trained for a number of iterations\n",
            " |              given by `epochs`, but merely until the epoch\n",
            " |              of index `epochs` is reached.\n",
            " |          verbose: 'auto', 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
            " |              'auto' defaults to 1 for most cases, but 2 when used with\n",
            " |              `ParameterServerStrategy`. Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so verbose=2 is\n",
            " |              recommended when not running interactively (eg, in a production\n",
            " |              environment).\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during training.\n",
            " |              See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
            " |              and `tf.keras.callbacks.History` callbacks are created automatically\n",
            " |              and need not be passed into `model.fit`.\n",
            " |              `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
            " |              `verbose` argument to `model.fit`.\n",
            " |              Callbacks with batch-level calls are currently unsupported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`, and users are\n",
            " |              advised to implement epoch-level calls instead with an appropriate\n",
            " |              `steps_per_epoch` value.\n",
            " |          validation_split: Float between 0 and 1.\n",
            " |              Fraction of the training data to be used as validation data.\n",
            " |              The model will set apart this fraction of the training data,\n",
            " |              will not train on it, and will evaluate\n",
            " |              the loss and any model metrics\n",
            " |              on this data at the end of each epoch.\n",
            " |              The validation data is selected from the last samples\n",
            " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
            " |              not supported when `x` is a dataset, generator or\n",
            " |             `keras.utils.Sequence` instance.\n",
            " |              `validation_split` is not yet supported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          validation_data: Data on which to evaluate\n",
            " |              the loss and any model metrics at the end of each epoch.\n",
            " |              The model will not be trained on this data. Thus, note the fact\n",
            " |              that the validation loss of data provided using `validation_split`\n",
            " |              or `validation_data` is not affected by regularization layers like\n",
            " |              noise and dropout.\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |              `validation_data` could be:\n",
            " |                - A tuple `(x_val, y_val)` of Numpy arrays or tensors.\n",
            " |                - A tuple `(x_val, y_val, val_sample_weights)` of NumPy arrays.\n",
            " |                - A `tf.data.Dataset`.\n",
            " |                - A Python generator or `keras.utils.Sequence` returning\n",
            " |                `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
            " |              `validation_data` is not yet supported with\n",
            " |              `tf.distribute.experimental.ParameterServerStrategy`.\n",
            " |          shuffle: Boolean (whether to shuffle the training data\n",
            " |              before each epoch) or str (for 'batch'). This argument is ignored\n",
            " |              when `x` is a generator or an object of tf.data.Dataset.\n",
            " |              'batch' is a special option for dealing\n",
            " |              with the limitations of HDF5 data; it shuffles in batch-sized\n",
            " |              chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |              to a weight (float) value, used for weighting the loss function\n",
            " |              (during training only).\n",
            " |              This can be useful to tell the model to\n",
            " |              \"pay more attention\" to samples from\n",
            " |              an under-represented class.\n",
            " |          sample_weight: Optional Numpy array of weights for\n",
            " |              the training samples, used for weighting the loss function\n",
            " |              (during training only). You can either pass a flat (1D)\n",
            " |              Numpy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples),\n",
            " |              or in the case of temporal data,\n",
            " |              you can pass a 2D array with shape\n",
            " |              `(samples, sequence_length)`,\n",
            " |              to apply a different weight to every timestep of every sample. This\n",
            " |              argument is not supported when `x` is a dataset, generator, or\n",
            " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
            " |              as the third element of `x`.\n",
            " |          initial_epoch: Integer.\n",
            " |              Epoch at which to start training\n",
            " |              (useful for resuming a previous training run).\n",
            " |          steps_per_epoch: Integer or `None`.\n",
            " |              Total number of steps (batches of samples)\n",
            " |              before declaring one epoch finished and starting the\n",
            " |              next epoch. When training with input tensors such as\n",
            " |              TensorFlow data tensors, the default `None` is equal to\n",
            " |              the number of samples in your dataset divided by\n",
            " |              the batch size, or 1 if that cannot be determined. If x is a\n",
            " |              `tf.data` dataset, and 'steps_per_epoch'\n",
            " |              is None, the epoch will run until the input dataset is exhausted.\n",
            " |              When passing an infinitely repeating dataset, you must specify the\n",
            " |              `steps_per_epoch` argument. If `steps_per_epoch=-1` the training\n",
            " |              will run indefinitely with an infinitely repeating dataset.\n",
            " |              This argument is not supported with array inputs.\n",
            " |              When using `tf.distribute.experimental.ParameterServerStrategy`:\n",
            " |                * `steps_per_epoch=None` is not supported.\n",
            " |          validation_steps: Only relevant if `validation_data` is provided and\n",
            " |              is a `tf.data` dataset. Total number of steps (batches of\n",
            " |              samples) to draw before stopping when performing validation\n",
            " |              at the end of every epoch. If 'validation_steps' is None, validation\n",
            " |              will run until the `validation_data` dataset is exhausted. In the\n",
            " |              case of an infinitely repeated dataset, it will run into an\n",
            " |              infinite loop. If 'validation_steps' is specified and only part of\n",
            " |              the dataset will be consumed, the evaluation will start from the\n",
            " |              beginning of the dataset at each epoch. This ensures that the same\n",
            " |              validation samples are used every time.\n",
            " |          validation_batch_size: Integer or `None`.\n",
            " |              Number of samples per validation batch.\n",
            " |              If unspecified, will default to `batch_size`.\n",
            " |              Do not specify the `validation_batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          validation_freq: Only relevant if validation data is provided. Integer\n",
            " |              or `collections.abc.Container` instance (e.g. list, tuple, etc.).\n",
            " |              If an integer, specifies how many training epochs to run before a\n",
            " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
            " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
            " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
            " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |              input only. Maximum size for the generator queue.\n",
            " |              If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up\n",
            " |              when using process-based threading. If unspecified, `workers`\n",
            " |              will default to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children processes.\n",
            " |      \n",
            " |      Unpacking behavior for iterator-like inputs:\n",
            " |          A common pattern is to pass a tf.data.Dataset, generator, or\n",
            " |        tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
            " |        yield not only features (x) but optionally targets (y) and sample weights.\n",
            " |        Keras requires that the output of such iterator-likes be unambiguous. The\n",
            " |        iterator should return a tuple of length 1, 2, or 3, where the optional\n",
            " |        second and third elements will be used for y and sample_weight\n",
            " |        respectively. Any other type provided will be wrapped in a length one\n",
            " |        tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
            " |        should still adhere to the top-level tuple structure.\n",
            " |        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
            " |        features, targets, and weights from the keys of a single dict.\n",
            " |          A notable unsupported data type is the namedtuple. The reason is that\n",
            " |        it behaves like both an ordered datatype (tuple) and a mapping\n",
            " |        datatype (dict). So given a namedtuple of the form:\n",
            " |            `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
            " |        it is ambiguous whether to reverse the order of the elements when\n",
            " |        interpreting the value. Even worse is a tuple of the form:\n",
            " |            `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
            " |        where it is unclear if the tuple was intended to be unpacked into x, y,\n",
            " |        and sample_weight or passed through as a single element to `x`. As a\n",
            " |        result the data processing code will simply raise a ValueError if it\n",
            " |        encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `History` object. Its `History.history` attribute is\n",
            " |          a record of training loss values and metrics values\n",
            " |          at successive epochs, as well as validation loss values\n",
            " |          and validation metrics values (if applicable).\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: 1. If the model was never compiled or,\n",
            " |          2. If `model.fit` is  wrapped in `tf.function`.\n",
            " |      \n",
            " |          ValueError: In case of mismatch between the provided input data\n",
            " |              and what the model expects or when the input data is empty.\n",
            " |  \n",
            " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
            " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.fit` now supports generators, so there is no longer any need to use\n",
            " |        this endpoint.\n",
            " |  \n",
            " |  get_layer(self, name=None, index=None)\n",
            " |      Retrieves a layer based on either its name (unique) or index.\n",
            " |      \n",
            " |      If `name` and `index` are both provided, `index` will take precedence.\n",
            " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            " |      \n",
            " |      Args:\n",
            " |          name: String, name of layer.\n",
            " |          index: Integer, index of layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Retrieves the weights of the model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A flat list of Numpy arrays.\n",
            " |  \n",
            " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None)\n",
            " |      Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
            " |      \n",
            " |      If `by_name` is False weights are loaded based on the network's\n",
            " |      topology. This means the architecture should be the same as when the weights\n",
            " |      were saved.  Note that layers that don't have weights are not taken into\n",
            " |      account in the topological ordering, so adding or removing layers is fine as\n",
            " |      long as they don't have weights.\n",
            " |      \n",
            " |      If `by_name` is True, weights are loaded into layers only if they share the\n",
            " |      same name. This is useful for fine-tuning or transfer-learning models where\n",
            " |      some of the layers have changed.\n",
            " |      \n",
            " |      Only topological loading (`by_name=False`) is supported when loading weights\n",
            " |      from the TensorFlow format. Note that topological loading differs slightly\n",
            " |      between TensorFlow and HDF5 formats for user-defined classes inheriting from\n",
            " |      `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the\n",
            " |      TensorFlow format loads based on the object-local names of attributes to\n",
            " |      which layers are assigned in the `Model`'s constructor.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String, path to the weights file to load. For weight files in\n",
            " |              TensorFlow format, this is the file prefix (the same as was passed\n",
            " |              to `save_weights`). This can also be a path to a SavedModel\n",
            " |              saved from `model.save`.\n",
            " |          by_name: Boolean, whether to load weights by name or by topological\n",
            " |              order. Only topological loading is supported for weight files in\n",
            " |              TensorFlow format.\n",
            " |          skip_mismatch: Boolean, whether to skip loading of layers where there is\n",
            " |              a mismatch in the number of weights, or a mismatch in the shape of\n",
            " |              the weight (only valid when `by_name=True`).\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for loading weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          When loading a weight file in TensorFlow format, returns the same status\n",
            " |          object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
            " |          ops are run automatically as soon as the network is built (on first call\n",
            " |          for user-defined classes inheriting from `Model`, immediately if it is\n",
            " |          already built).\n",
            " |      \n",
            " |          When loading weights in HDF5 format, returns `None`.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If `h5py` is not available and the weight file is in HDF5\n",
            " |              format.\n",
            " |          ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
            " |            `False`.\n",
            " |  \n",
            " |  make_predict_function(self, force=False)\n",
            " |      Creates a function that executes one step of inference.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.predict` and `Model.predict_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.predict_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.predict` or\n",
            " |      `Model.predict_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the predict function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return the outputs of the `Model`.\n",
            " |  \n",
            " |  make_test_function(self, force=False)\n",
            " |      Creates a function that executes one step of evaluation.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.evaluate` and `Model.test_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual evaluation\n",
            " |      logic to `Model.test_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.evaluate` or\n",
            " |      `Model.test_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the test function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_test_batch_end`.\n",
            " |  \n",
            " |  make_train_function(self, force=False)\n",
            " |      Creates a function that executes one step of training.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      This method is called by `Model.fit` and `Model.train_on_batch`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings, and delegates the actual training\n",
            " |      logic to `Model.train_step`.\n",
            " |      \n",
            " |      This function is cached the first time `Model.fit` or\n",
            " |      `Model.train_on_batch` is called. The cache is cleared whenever\n",
            " |      `Model.compile` is called. You can skip the cache and generate again the\n",
            " |      function with `force=True`.\n",
            " |      \n",
            " |      Args:\n",
            " |        force: Whether to regenerate the train function and skip the cached\n",
            " |          function if available.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, and return a `dict` containing values that will\n",
            " |        be passed to `tf.keras.Callbacks.on_train_batch_end`, such as\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
            " |      Generates output predictions for the input samples.\n",
            " |      \n",
            " |      Computation is done in batches. This method is designed for batch processing\n",
            " |      of large numbers of inputs. It is not intended for use inside of loops\n",
            " |      that iterate over your data and process small numbers of inputs at a time.\n",
            " |      \n",
            " |      For small numbers of inputs that fit in one batch,\n",
            " |      directly use `__call__()` for faster execution, e.g.,\n",
            " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            " |      `tf.keras.layers.BatchNormalization` that behave differently during\n",
            " |      inference. You may pair the individual model call with a `tf.function`\n",
            " |      for additional performance inside your inner loop.\n",
            " |      If you need access to numpy array values instead of tensors after your\n",
            " |      model call, you can use `tensor.numpy()` to get the numpy array value of\n",
            " |      an eager tensor.\n",
            " |      \n",
            " |      Also, note the fact that test loss is not affected by\n",
            " |      regularization layers like noise and dropout.\n",
            " |      \n",
            " |      Note: See [this FAQ entry](\n",
            " |      https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
            " |      for more details about the difference between `Model` methods `predict()`\n",
            " |      and `__call__()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input samples. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |            - A `tf.data` dataset.\n",
            " |            - A generator or `keras.utils.Sequence` instance.\n",
            " |            A more detailed description of unpacking behavior for iterator types\n",
            " |            (Dataset, generator, Sequence) is given in the `Unpacking behavior\n",
            " |            for iterator-like inputs` section of `Model.fit`.\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per batch.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of dataset, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          verbose: Verbosity mode, 0 or 1.\n",
            " |          steps: Total number of steps (batches of samples)\n",
            " |              before declaring the prediction round finished.\n",
            " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
            " |              dataset and `steps` is None, `predict()` will\n",
            " |              run until the input dataset is exhausted.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during prediction.\n",
            " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
            " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
            " |              input only. Maximum size for the generator queue.\n",
            " |              If unspecified, `max_queue_size` will default to 10.\n",
            " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
            " |              only. Maximum number of processes to spin up when using\n",
            " |              process-based threading. If unspecified, `workers` will default\n",
            " |              to 1.\n",
            " |          use_multiprocessing: Boolean. Used for generator or\n",
            " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
            " |              threading. If unspecified, `use_multiprocessing` will default to\n",
            " |              `False`. Note that because this implementation relies on\n",
            " |              multiprocessing, you should not pass non-picklable arguments to\n",
            " |              the generator as they can't be passed easily to children processes.\n",
            " |      \n",
            " |      See the discussion of `Unpacking behavior for iterator-like inputs` for\n",
            " |      `Model.fit`. Note that Model.predict uses the same interpretation rules as\n",
            " |      `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all\n",
            " |      three methods.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict` is wrapped in a `tf.function`.\n",
            " |          ValueError: In case of mismatch between the provided\n",
            " |              input data and the model's expectations,\n",
            " |              or in case a stateful model receives a number of samples\n",
            " |              that is not a multiple of the batch size.\n",
            " |  \n",
            " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
            " |      Generates predictions for the input samples from a data generator.\n",
            " |      \n",
            " |      DEPRECATED:\n",
            " |        `Model.predict` now supports generators, so there is no longer any need\n",
            " |        to use this endpoint.\n",
            " |  \n",
            " |  predict_on_batch(self, x)\n",
            " |      Returns predictions for a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |      \n",
            " |      Returns:\n",
            " |          Numpy array(s) of predictions.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.predict_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  predict_step(self, data)\n",
            " |      The logic for one inference step.\n",
            " |      \n",
            " |      This method can be overridden to support custom inference logic.\n",
            " |      This method is called by `Model.make_predict_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of inference.\n",
            " |      This typically includes the forward pass.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_predict_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of one inference step, typically the output of calling the\n",
            " |        `Model` on data.\n",
            " |  \n",
            " |  reset_metrics(self)\n",
            " |      Resets the state of all the metrics in the model.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> _ = model.fit(x, y, verbose=0)\n",
            " |      >>> assert all(float(m.result()) for m in model.metrics)\n",
            " |      \n",
            " |      >>> model.reset_metrics()\n",
            " |      >>> assert all(float(m.result()) == 0 for m in model.metrics)\n",
            " |  \n",
            " |  reset_states(self)\n",
            " |  \n",
            " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None, save_traces=True)\n",
            " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
            " |      \n",
            " |      Please see `tf.keras.models.save_model` or the\n",
            " |      [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)\n",
            " |      for details.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String, PathLike, path to SavedModel or H5 file to save the\n",
            " |              model.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          include_optimizer: If True, save optimizer's state together.\n",
            " |          save_format: Either `'tf'` or `'h5'`, indicating whether to save the\n",
            " |              model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,\n",
            " |              and 'h5' in TF 1.X.\n",
            " |          signatures: Signatures to save with the SavedModel. Applicable to the\n",
            " |              'tf' format only. Please see the `signatures` argument in\n",
            " |              `tf.saved_model.save` for details.\n",
            " |          options: (only applies to SavedModel format)\n",
            " |              `tf.saved_model.SaveOptions` object that specifies options for\n",
            " |              saving to SavedModel.\n",
            " |          save_traces: (only applies to SavedModel format) When enabled, the\n",
            " |              SavedModel will store the function traces for each layer. This\n",
            " |              can be disabled, so that only the configs of each layer are stored.\n",
            " |              Defaults to `True`. Disabling this will decrease serialization time\n",
            " |              and reduce file size, but it requires that all custom layers/models\n",
            " |              implement a `get_config()` method.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      from keras.models import load_model\n",
            " |      \n",
            " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
            " |      del model  # deletes the existing model\n",
            " |      \n",
            " |      # returns a compiled model\n",
            " |      # identical to the previous one\n",
            " |      model = load_model('my_model.h5')\n",
            " |      ```\n",
            " |  \n",
            " |  save_spec(self, dynamic_batch=True)\n",
            " |      Returns the `tf.TensorSpec` of call inputs as a tuple `(args, kwargs)`.\n",
            " |      \n",
            " |      This value is automatically defined after calling the model for the first\n",
            " |      time. Afterwards, you can use it when exporting the model for serving:\n",
            " |      \n",
            " |      ```python\n",
            " |      model = tf.keras.Model(...)\n",
            " |      \n",
            " |      @tf.function\n",
            " |      def serve(*args, **kwargs):\n",
            " |        outputs = model(*args, **kwargs)\n",
            " |        # Apply postprocessing steps, or add additional outputs.\n",
            " |        ...\n",
            " |        return outputs\n",
            " |      \n",
            " |      # arg_specs is `[tf.TensorSpec(...), ...]`. kwarg_specs, in this example, is\n",
            " |      # an empty dict since functional models do not use keyword arguments.\n",
            " |      arg_specs, kwarg_specs = model.save_spec()\n",
            " |      \n",
            " |      model.save(path, signatures={\n",
            " |        'serving_default': serve.get_concrete_function(*arg_specs, **kwarg_specs)\n",
            " |      })\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        dynamic_batch: Whether to set the batch sizes of all the returned\n",
            " |          `tf.TensorSpec` to `None`. (Note that when defining functional or\n",
            " |          Sequential models with `tf.keras.Input([...], batch_size=X)`, the\n",
            " |          batch size will always be preserved). Defaults to `True`.\n",
            " |      Returns:\n",
            " |        If the model inputs are defined, returns a tuple `(args, kwargs)`. All\n",
            " |        elements in `args` and `kwargs` are `tf.TensorSpec`.\n",
            " |        If the model inputs are not defined, returns `None`.\n",
            " |        The model inputs are automatically set when calling the model,\n",
            " |        `model.fit`, `model.evaluate` or `model.predict`.\n",
            " |  \n",
            " |  save_weights(self, filepath, overwrite=True, save_format=None, options=None)\n",
            " |      Saves all layer weights.\n",
            " |      \n",
            " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
            " |      argument.\n",
            " |      \n",
            " |      When saving in HDF5 format, the weight file has:\n",
            " |        - `layer_names` (attribute), a list of strings\n",
            " |            (ordered names of model layers).\n",
            " |        - For every layer, a `group` named `layer.name`\n",
            " |            - For every such layer group, a group attribute `weight_names`,\n",
            " |                a list of strings\n",
            " |                (ordered names of weights tensor of the layer).\n",
            " |            - For every weight in the layer, a dataset\n",
            " |                storing the weight value, named after the weight tensor.\n",
            " |      \n",
            " |      When saving in TensorFlow format, all objects referenced by the network are\n",
            " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
            " |      instances or `Optimizer` instances assigned to object attributes. For\n",
            " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
            " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
            " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
            " |      `Layer` instances must be assigned to object attributes, typically in the\n",
            " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
            " |      `tf.keras.Model` for details.\n",
            " |      \n",
            " |      While the formats are the same, do not mix `save_weights` and\n",
            " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
            " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
            " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
            " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
            " |      `save_weights` for training checkpoints.\n",
            " |      \n",
            " |      The TensorFlow format matches objects and variables by starting at a root\n",
            " |      object, `self` for `save_weights`, and greedily matching attribute\n",
            " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
            " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
            " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
            " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
            " |      the `Model`'s variables. See the\n",
            " |      [guide to training checkpoints](https://www.tensorflow.org/guide/checkpoint)\n",
            " |      for details on the TensorFlow format.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String or PathLike, path to the file to save the weights to.\n",
            " |              When saving in TensorFlow format, this is the prefix used for\n",
            " |              checkpoint files (multiple files are generated). Note that the '.h5'\n",
            " |              suffix causes weights to be saved in HDF5 format.\n",
            " |          overwrite: Whether to silently overwrite any existing file at the\n",
            " |              target location, or provide the user with a manual prompt.\n",
            " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
            " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
            " |              `None` defaults to 'tf'.\n",
            " |          options: Optional `tf.train.CheckpointOptions` object that specifies\n",
            " |              options for saving weights.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If `h5py` is not available when attempting to save in HDF5\n",
            " |              format.\n",
            " |  \n",
            " |  summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False)\n",
            " |      Prints a string summary of the network.\n",
            " |      \n",
            " |      Args:\n",
            " |          line_length: Total length of printed lines\n",
            " |              (e.g. set this to adapt the display to different\n",
            " |              terminal window sizes).\n",
            " |          positions: Relative or absolute positions of log elements\n",
            " |              in each line. If not provided,\n",
            " |              defaults to `[.33, .55, .67, 1.]`.\n",
            " |          print_fn: Print function to use. Defaults to `print`.\n",
            " |              It will be called on each line of the summary.\n",
            " |              You can set it to a custom function\n",
            " |              in order to capture the string summary.\n",
            " |          expand_nested: Whether to expand the nested models.\n",
            " |              If not provided, defaults to `False`.\n",
            " |          show_trainable: Whether to show if a layer is trainable.\n",
            " |              If not provided, defaults to `False`.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if `summary()` is called before the model is built.\n",
            " |  \n",
            " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Test the model on a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays (in case the\n",
            " |                model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors (in case the model has\n",
            " |                multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors, if\n",
            " |                the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `model.test_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  test_step(self, data)\n",
            " |      The logic for one evaluation step.\n",
            " |      \n",
            " |      This method can be overridden to support custom evaluation logic.\n",
            " |      This method is called by `Model.make_test_function`.\n",
            " |      \n",
            " |      This function should contain the mathematical logic for one step of\n",
            " |      evaluation.\n",
            " |      This typically includes the forward pass, loss calculation, and metrics\n",
            " |      updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_test_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned.\n",
            " |  \n",
            " |  to_json(self, **kwargs)\n",
            " |      Returns a JSON string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a JSON save file, use\n",
            " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `json.dumps()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON string.\n",
            " |  \n",
            " |  to_yaml(self, **kwargs)\n",
            " |      Returns a yaml string containing the network configuration.\n",
            " |      \n",
            " |      Note: Since TF 2.6, this method is no longer supported and will raise a\n",
            " |      RuntimeError.\n",
            " |      \n",
            " |      To load a network from a yaml save file, use\n",
            " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
            " |      \n",
            " |      `custom_objects` should be a dictionary mapping\n",
            " |      the names of custom losses / layers / etc to the corresponding\n",
            " |      functions / classes.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `yaml.dump()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A YAML string.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: announces that the method poses a security risk\n",
            " |  \n",
            " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True, return_dict=False)\n",
            " |      Runs a single gradient update on a single batch of data.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |            - A Numpy array (or array-like), or a list of arrays\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A TensorFlow tensor, or a list of tensors\n",
            " |                (in case the model has multiple inputs).\n",
            " |            - A dict mapping input names to the corresponding array/tensors,\n",
            " |                if the model has named inputs.\n",
            " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
            " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
            " |            (you cannot have Numpy inputs and tensor targets, or inversely).\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |            weights to apply to the model's loss for each sample. In the case of\n",
            " |            temporal data, you can pass a 2D array with shape (samples,\n",
            " |            sequence_length), to apply a different weight to every timestep of\n",
            " |            every sample.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
            " |            weight (float) to apply to the model's loss for the samples from this\n",
            " |            class during training. This can be useful to tell the model to \"pay\n",
            " |            more attention\" to samples from an under-represented class.\n",
            " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
            " |            batch. If `False`, the metrics will be statefully accumulated across\n",
            " |            batches.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a dict,\n",
            " |            with each key being the name of the metric. If `False`, they are\n",
            " |            returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar training loss\n",
            " |          (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If `model.train_on_batch` is wrapped in a `tf.function`.\n",
            " |  \n",
            " |  train_step(self, data)\n",
            " |      The logic for one training step.\n",
            " |      \n",
            " |      This method can be overridden to support custom training logic.\n",
            " |      For concrete examples of how to override this method see\n",
            " |      [Customizing what happends in fit](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n",
            " |      This method is called by `Model.make_train_function`.\n",
            " |      \n",
            " |      This method should contain the mathematical logic for one step of training.\n",
            " |      This typically includes the forward pass, loss calculation, backpropagation,\n",
            " |      and metric updates.\n",
            " |      \n",
            " |      Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
            " |      `tf.distribute.Strategy` settings), should be left to\n",
            " |      `Model.make_train_function`, which can also be overridden.\n",
            " |      \n",
            " |      Args:\n",
            " |        data: A nested structure of `Tensor`s.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `dict` containing values that will be passed to\n",
            " |        `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
            " |        values of the `Model`'s metrics are returned. Example:\n",
            " |        `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.training.Model:\n",
            " |  \n",
            " |  distribute_strategy\n",
            " |      The `tf.distribute.Strategy` this model was created under.\n",
            " |  \n",
            " |  metrics\n",
            " |      Returns the model's metrics added using `compile()`, `add_metric()` APIs.\n",
            " |      \n",
            " |      Note: Metrics passed to `compile()` are available only after a `keras.Model`\n",
            " |      has been trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.add_metric(\n",
            " |      ...    tf.reduce_sum(output_2), name='mean', aggregation='mean')\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> [m.name for m in model.metrics]\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc', 'mean']\n",
            " |  \n",
            " |  metrics_names\n",
            " |      Returns the model's display labels for all outputs.\n",
            " |      \n",
            " |      Note: `metrics_names` are available only after a `keras.Model` has been\n",
            " |      trained/evaluated on actual data.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> outputs = tf.keras.layers.Dense(2)(inputs)\n",
            " |      >>> model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])\n",
            " |      >>> model.metrics_names\n",
            " |      []\n",
            " |      \n",
            " |      >>> x = np.random.random((2, 3))\n",
            " |      >>> y = np.random.randint(0, 2, (2, 2))\n",
            " |      >>> model.fit(x, y)\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'mae']\n",
            " |      \n",
            " |      >>> inputs = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2, name='out')\n",
            " |      >>> output_1 = d(inputs)\n",
            " |      >>> output_2 = d(inputs)\n",
            " |      >>> model = tf.keras.models.Model(\n",
            " |      ...    inputs=inputs, outputs=[output_1, output_2])\n",
            " |      >>> model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\", \"acc\"])\n",
            " |      >>> model.fit(x, (y, y))\n",
            " |      >>> model.metrics_names\n",
            " |      ['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',\n",
            " |      'out_1_acc']\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are expected\n",
            " |      to be updated manually in `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  run_eagerly\n",
            " |      Settable attribute indicating whether the model should run eagerly.\n",
            " |      \n",
            " |      Running eagerly means that your model will be run step by step,\n",
            " |      like Python code. Your model might run slower, but it should become easier\n",
            " |      for you to debug it by stepping into individual layer calls.\n",
            " |      \n",
            " |      By default, we will attempt to compile your model to a static graph to\n",
            " |      deliver the best execution performance.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Boolean, whether the model should run eagerly.\n",
            " |  \n",
            " |  state_updates\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Returns the `updates` from all layers that are stateful.\n",
            " |      \n",
            " |      This is useful for separating training updates and\n",
            " |      state updates, e.g. when we need to update a layer's internal state\n",
            " |      during prediction.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A list of update ops.\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |      Wraps `call`, applying pre- and post-processing steps.\n",
            " |      \n",
            " |      Args:\n",
            " |        *args: Positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |      \n",
            " |      Note:\n",
            " |        - The following optional keyword arguments are reserved for specific uses:\n",
            " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          * `mask`: Boolean input mask.\n",
            " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            " |          layers do), its default value will be set to the mask generated\n",
            " |          for `inputs` by the previous layer (if `input` did come from\n",
            " |          a layer that generated a corresponding mask, i.e. if it came from\n",
            " |          a Keras layer with masking support.\n",
            " |        - If the layer is not built, the method will call `build`.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, **kwargs)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be dependent\n",
            " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(self, inputs):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any loss Tensors passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      losses become part of the model's topology and are tracked in `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss references\n",
            " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            " |      topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      d = tf.keras.layers.Dense(10)\n",
            " |      x = d(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            " |          may also be zero-argument callables which create a loss tensor.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |            inputs - Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_metric(self, value, name=None, **kwargs)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      This method can be used inside the `call()` method of a subclassed layer\n",
            " |      or model.\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            " |        def __init__(self):\n",
            " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          self.add_metric(self.mean(inputs))\n",
            " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any tensor passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      metrics become part of the model's topology and are tracked when you\n",
            " |      save the model via `save()`.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            " |      Functional Model, as shown in the example below, is not supported. This is\n",
            " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        name: String metric name.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |          `aggregation` - When the `value` tensor provided is not the result of\n",
            " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
            " |          using a `keras.Metric.Mean`.\n",
            " |  \n",
            " |  add_update(self, updates, inputs=None)\n",
            " |      Add update op(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and variance\n",
            " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            " |      when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case, variable\n",
            " |      updates are run on the fly and thus do not need to be tracked for later\n",
            " |      execution).\n",
            " |      \n",
            " |      Args:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |        inputs: Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        use_resource: Whether to use `ResourceVariable`.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses\n",
            " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            " |          `trainable` must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The variable created.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            " |  \n",
            " |  apply(self, inputs, *args, **kwargs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      This is an alias of `self.__call__`.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor(s).\n",
            " |        *args: additional positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            " |          how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  finalize_state(self)\n",
            " |      Finalizes the layers state after updating layer weights.\n",
            " |      \n",
            " |      This function can be subclassed in a layer and will be called after updating\n",
            " |      a layer weights. It can be overridden to finalize any additional layer state\n",
            " |      after a weight update.\n",
            " |      \n",
            " |      This function will be called after weights of a layer have been restored\n",
            " |      from a loaded model.\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first input node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_losses_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves losses relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of loss tensors of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first output node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_updates_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves updates relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of update ops of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function, by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
            " |      and the bias vector. These can be used to set the weights of another\n",
            " |      `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Args:\n",
            " |        weights: a list of NumPy arrays. The number\n",
            " |          of arrays and their shape must match\n",
            " |          number of the dimensions of the weights\n",
            " |          of the layer (i.e. it should match the\n",
            " |          output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If the provided weights list does not match the\n",
            " |          layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the layer's computations.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
            " |      the weights.\n",
            " |      \n",
            " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
            " |      computations and the output to be in the compute dtype as well. This is done\n",
            " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
            " |      these casts if implementing your own layer.\n",
            " |      \n",
            " |      Layers often perform certain internal computations in higher precision when\n",
            " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
            " |      will still typically be float16 or bfloat16 in such cases.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The layer's compute dtype.\n",
            " |  \n",
            " |  dtype\n",
            " |      The dtype of the layer weights.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
            " |      dtype of the layer's computations.\n",
            " |  \n",
            " |  dtype_policy\n",
            " |      The dtype policy associated with this layer.\n",
            " |      \n",
            " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  losses\n",
            " |      List of losses added using the `add_loss()` API.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is accessed,\n",
            " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            " |      propagate gradients back to the corresponding variables.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            " |      ...   def call(self, inputs):\n",
            " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |      ...     return inputs\n",
            " |      >>> l = MyLayer()\n",
            " |      >>> l(np.ones((10, 1)))\n",
            " |      >>> l.losses\n",
            " |      [1.0]\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Activity regularization.\n",
            " |      >>> len(model.losses)\n",
            " |      0\n",
            " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      >>> len(model.losses)\n",
            " |      1\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            " |      >>> x = d(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Weight regularization.\n",
            " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      >>> model.losses\n",
            " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "c8pihuhRlwrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff28cb72-c815-46dd-a032-70b637fdca97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.8213750123977661,\n",
              "  0.8607083559036255,\n",
              "  0.8762083053588867,\n",
              "  0.883187472820282,\n",
              "  0.890791654586792,\n",
              "  0.8944583535194397,\n",
              "  0.8995000123977661,\n",
              "  0.9032708406448364,\n",
              "  0.9051250219345093,\n",
              "  0.909375011920929],\n",
              " 'loss': [0.49696362018585205,\n",
              "  0.3763921856880188,\n",
              "  0.3387308418750763,\n",
              "  0.3167855143547058,\n",
              "  0.2976021468639374,\n",
              "  0.28374552726745605,\n",
              "  0.26834362745285034,\n",
              "  0.26018285751342773,\n",
              "  0.24864201247692108,\n",
              "  0.24164114892482758],\n",
              " 'val_accuracy': [0.8601666688919067,\n",
              "  0.8685833215713501,\n",
              "  0.8688333630561829,\n",
              "  0.8776666522026062,\n",
              "  0.8790000081062317,\n",
              "  0.8765833377838135,\n",
              "  0.8801666498184204,\n",
              "  0.8835833072662354,\n",
              "  0.8838333487510681,\n",
              "  0.8858333230018616],\n",
              " 'val_loss': [0.3944215476512909,\n",
              "  0.36546358466148376,\n",
              "  0.35869458317756653,\n",
              "  0.35105037689208984,\n",
              "  0.33201444149017334,\n",
              "  0.3469325006008148,\n",
              "  0.3440174162387848,\n",
              "  0.325324684381485,\n",
              "  0.3301360607147217,\n",
              "  0.32906636595726013]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5AOajSWtlwrK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iMtK5muylwrK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b1f2caea-e0a0-43c9-f586-a084ddd84a27"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot training and validation accuracy values\n",
        "# Train vs Test\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WxqP3R6UlwrL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1a26553d-3464-41ce-da09-684e44ae4750"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot training and validation loss values\n",
        "# Train vs Test\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Tensorflow - Basic Image Classification MNIST Dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
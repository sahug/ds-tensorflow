{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow - Tune Hyperparameter with Keras Tuner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPc/ZcPlwYjEqAijQK8oczX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahug/ds-tensorflow-colab/blob/master/Tensorflow%20-%20Tune%20Hyperparameter%20with%20Keras%20Tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensorflow - Tune Hyperparameter with Keras Tuner**"
      ],
      "metadata": {
        "id": "KGRJYY4jnldA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ],
      "metadata": {
        "id": "P8Ry8OK_uvCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "zIw4K4rSuuhB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMLmGbREu-Od",
        "outputId": "d046744c-253e-452b-822d-ca9490cea64f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 20.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 8.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "eXiizPbZx9YU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download and prepare the dataset**"
      ],
      "metadata": {
        "id": "eQ-CwWxmyCDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJDPrZMkyEAN",
        "outputId": "ca62a4d9-5352-4456-986d-431aea091bc5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values between 0 and 1\n",
        "img_train = img_train.astype('float32') / 255.0\n",
        "img_test = img_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "Fes38jYhyKG9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the model**\n",
        "\n",
        "When you build a model for hypertuning, you also define the hyperparameter search space in addition to the model architecture. The model you set up for hypertuning is called a hypermodel.\n",
        "\n",
        "You can define a hypermodel through two approaches:\n",
        "\n",
        "- By using a model builder function\n",
        "- By subclassing the HyperModel class of the Keras Tuner API"
      ],
      "metadata": {
        "id": "d_MYTDnkyLqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "vlaskpAGyVTD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instantiate the tuner and perform hypertuning**"
      ],
      "metadata": {
        "id": "UhAgSmQbyfXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "metadata": {
        "id": "CxgOdLSZyh64"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a **callback** to stop training early after reaching a certain value for the validation loss."
      ],
      "metadata": {
        "id": "ZYE9j7hmyksB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "Y8GfQcY_ymVJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the **hyperparameter search**. The arguments for the search method are the same as those used for **tf.keras.model.fit in addition to the callback above**."
      ],
      "metadata": {
        "id": "OHK01dtTyzNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeRboAHHyoaU",
        "outputId": "bdb84379-fc1e-42f6-c140-fb355e057ba2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 01m 15s]\n",
            "val_accuracy: 0.8815000057220459\n",
            "\n",
            "Best val_accuracy So Far: 0.8866666555404663\n",
            "Total elapsed time: 00h 14m 28s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 480 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**\n",
        "\n",
        "Find the optimal number of epochs to train the model with the hyperparameters obtained from the search."
      ],
      "metadata": {
        "id": "iD2bcQrd3Bk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBuHD3SH3EQb",
        "outputId": "404577b8-479a-4c47-eef9-912f4ab9b23a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4945 - accuracy: 0.8238 - val_loss: 0.4002 - val_accuracy: 0.8542\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3695 - accuracy: 0.8650 - val_loss: 0.3603 - val_accuracy: 0.8709\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3336 - accuracy: 0.8762 - val_loss: 0.3395 - val_accuracy: 0.8773\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3049 - accuracy: 0.8871 - val_loss: 0.3235 - val_accuracy: 0.8835\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2893 - accuracy: 0.8930 - val_loss: 0.3261 - val_accuracy: 0.8804\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2731 - accuracy: 0.8985 - val_loss: 0.3288 - val_accuracy: 0.8830\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2576 - accuracy: 0.9034 - val_loss: 0.3267 - val_accuracy: 0.8856\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2454 - accuracy: 0.9085 - val_loss: 0.3264 - val_accuracy: 0.8863\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2359 - accuracy: 0.9106 - val_loss: 0.3200 - val_accuracy: 0.8882\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2246 - accuracy: 0.9161 - val_loss: 0.3388 - val_accuracy: 0.8805\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2161 - accuracy: 0.9181 - val_loss: 0.3361 - val_accuracy: 0.8844\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2089 - accuracy: 0.9212 - val_loss: 0.3131 - val_accuracy: 0.8878\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2017 - accuracy: 0.9244 - val_loss: 0.3286 - val_accuracy: 0.8878\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1922 - accuracy: 0.9278 - val_loss: 0.3394 - val_accuracy: 0.8913\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1843 - accuracy: 0.9307 - val_loss: 0.3261 - val_accuracy: 0.8962\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1787 - accuracy: 0.9316 - val_loss: 0.3298 - val_accuracy: 0.8947\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1715 - accuracy: 0.9349 - val_loss: 0.3334 - val_accuracy: 0.8929\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1667 - accuracy: 0.9374 - val_loss: 0.3337 - val_accuracy: 0.8921\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1620 - accuracy: 0.9396 - val_loss: 0.3375 - val_accuracy: 0.8943\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1558 - accuracy: 0.9410 - val_loss: 0.3756 - val_accuracy: 0.8888\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1526 - accuracy: 0.9421 - val_loss: 0.3479 - val_accuracy: 0.8940\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1475 - accuracy: 0.9444 - val_loss: 0.3465 - val_accuracy: 0.8963\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1410 - accuracy: 0.9474 - val_loss: 0.3792 - val_accuracy: 0.8902\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1408 - accuracy: 0.9470 - val_loss: 0.3813 - val_accuracy: 0.8898\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1347 - accuracy: 0.9498 - val_loss: 0.3778 - val_accuracy: 0.8903\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1290 - accuracy: 0.9513 - val_loss: 0.4084 - val_accuracy: 0.8879\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1293 - accuracy: 0.9523 - val_loss: 0.3846 - val_accuracy: 0.8938\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1244 - accuracy: 0.9538 - val_loss: 0.3887 - val_accuracy: 0.8975\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1201 - accuracy: 0.9558 - val_loss: 0.3963 - val_accuracy: 0.8867\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1178 - accuracy: 0.9564 - val_loss: 0.3994 - val_accuracy: 0.8955\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1148 - accuracy: 0.9570 - val_loss: 0.4040 - val_accuracy: 0.8957\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1119 - accuracy: 0.9585 - val_loss: 0.3864 - val_accuracy: 0.8968\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.4284 - val_accuracy: 0.8905\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1074 - accuracy: 0.9589 - val_loss: 0.3972 - val_accuracy: 0.8975\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1025 - accuracy: 0.9614 - val_loss: 0.4722 - val_accuracy: 0.8904\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1045 - accuracy: 0.9610 - val_loss: 0.4456 - val_accuracy: 0.8972\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0956 - accuracy: 0.9636 - val_loss: 0.4564 - val_accuracy: 0.8899\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0923 - accuracy: 0.9646 - val_loss: 0.4547 - val_accuracy: 0.8928\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0946 - accuracy: 0.9645 - val_loss: 0.4536 - val_accuracy: 0.8952\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0905 - accuracy: 0.9661 - val_loss: 0.4858 - val_accuracy: 0.8887\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0875 - accuracy: 0.9672 - val_loss: 0.4854 - val_accuracy: 0.8907\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0876 - accuracy: 0.9672 - val_loss: 0.4861 - val_accuracy: 0.8921\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0866 - accuracy: 0.9676 - val_loss: 0.4905 - val_accuracy: 0.8942\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0808 - accuracy: 0.9693 - val_loss: 0.5291 - val_accuracy: 0.8911\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0872 - accuracy: 0.9679 - val_loss: 0.4805 - val_accuracy: 0.8963\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0792 - accuracy: 0.9694 - val_loss: 0.5242 - val_accuracy: 0.8897\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0750 - accuracy: 0.9724 - val_loss: 0.5517 - val_accuracy: 0.8861\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0780 - accuracy: 0.9710 - val_loss: 0.5088 - val_accuracy: 0.8940\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0739 - accuracy: 0.9726 - val_loss: 0.5476 - val_accuracy: 0.8931\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0727 - accuracy: 0.9725 - val_loss: 0.5818 - val_accuracy: 0.8907\n",
            "Best epoch: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-instantiate the hypermodel and train it with the optimal number of epochs from above."
      ],
      "metadata": {
        "id": "1zOXqGXV5DfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30YyZZpA5ELQ",
        "outputId": "5eecfa85-eaac-4d1c-fc2d-a6bf69a1000f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4932 - accuracy: 0.8256 - val_loss: 0.4031 - val_accuracy: 0.8518\n",
            "Epoch 2/28\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3667 - accuracy: 0.8661 - val_loss: 0.3797 - val_accuracy: 0.8602\n",
            "Epoch 3/28\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3297 - accuracy: 0.8780 - val_loss: 0.3356 - val_accuracy: 0.8792\n",
            "Epoch 4/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3031 - accuracy: 0.8879 - val_loss: 0.3502 - val_accuracy: 0.8735\n",
            "Epoch 5/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2829 - accuracy: 0.8945 - val_loss: 0.3249 - val_accuracy: 0.8869\n",
            "Epoch 6/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2696 - accuracy: 0.8984 - val_loss: 0.3127 - val_accuracy: 0.8891\n",
            "Epoch 7/28\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2561 - accuracy: 0.9047 - val_loss: 0.3375 - val_accuracy: 0.8806\n",
            "Epoch 8/28\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2426 - accuracy: 0.9086 - val_loss: 0.3308 - val_accuracy: 0.8842\n",
            "Epoch 9/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2334 - accuracy: 0.9126 - val_loss: 0.3456 - val_accuracy: 0.8800\n",
            "Epoch 10/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2220 - accuracy: 0.9177 - val_loss: 0.3234 - val_accuracy: 0.8900\n",
            "Epoch 11/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2127 - accuracy: 0.9199 - val_loss: 0.3305 - val_accuracy: 0.8878\n",
            "Epoch 12/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2070 - accuracy: 0.9232 - val_loss: 0.3253 - val_accuracy: 0.8879\n",
            "Epoch 13/28\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1968 - accuracy: 0.9266 - val_loss: 0.3412 - val_accuracy: 0.8876\n",
            "Epoch 14/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1929 - accuracy: 0.9280 - val_loss: 0.3124 - val_accuracy: 0.8951\n",
            "Epoch 15/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1841 - accuracy: 0.9309 - val_loss: 0.3219 - val_accuracy: 0.8939\n",
            "Epoch 16/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1789 - accuracy: 0.9335 - val_loss: 0.3283 - val_accuracy: 0.8954\n",
            "Epoch 17/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1713 - accuracy: 0.9360 - val_loss: 0.3169 - val_accuracy: 0.8958\n",
            "Epoch 18/28\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1679 - accuracy: 0.9369 - val_loss: 0.3794 - val_accuracy: 0.8795\n",
            "Epoch 19/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1561 - accuracy: 0.9414 - val_loss: 0.3437 - val_accuracy: 0.8965\n",
            "Epoch 20/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1554 - accuracy: 0.9426 - val_loss: 0.3539 - val_accuracy: 0.8892\n",
            "Epoch 21/28\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1510 - accuracy: 0.9435 - val_loss: 0.3479 - val_accuracy: 0.8960\n",
            "Epoch 22/28\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1451 - accuracy: 0.9464 - val_loss: 0.3469 - val_accuracy: 0.8965\n",
            "Epoch 23/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1404 - accuracy: 0.9483 - val_loss: 0.3540 - val_accuracy: 0.8955\n",
            "Epoch 24/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1381 - accuracy: 0.9485 - val_loss: 0.3501 - val_accuracy: 0.8976\n",
            "Epoch 25/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1343 - accuracy: 0.9498 - val_loss: 0.3549 - val_accuracy: 0.8984\n",
            "Epoch 26/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1279 - accuracy: 0.9523 - val_loss: 0.3862 - val_accuracy: 0.8921\n",
            "Epoch 27/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1250 - accuracy: 0.9520 - val_loss: 0.3777 - val_accuracy: 0.8966\n",
            "Epoch 28/28\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1226 - accuracy: 0.9536 - val_loss: 0.3891 - val_accuracy: 0.8948\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d8c6cea90>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To finish this tutorial, evaluate the hypermodel on the test data."
      ],
      "metadata": {
        "id": "IwphJSGa6LBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7jZo7lP6LnG",
        "outputId": "20f75165-f3e9-4b6f-e640-df6f0d135cd9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4478 - accuracy: 0.8866\n",
            "[test loss, test accuracy]: [0.4478291869163513, 0.8866000175476074]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **my_dir/intro_to_kt** directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. To disable this behavior, pass an additional **overwrite=True** argument while instantiating the tuner."
      ],
      "metadata": {
        "id": "wy92aiAQ6Rlw"
      }
    }
  ]
}
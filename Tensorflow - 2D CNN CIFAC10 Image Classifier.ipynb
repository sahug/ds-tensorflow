{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow - 2D CNN CIFAC10 Image Classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdTgFp8LQ0oQc2oHvCvUIf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahug/ds-tensorflow-colab/blob/master/Tensorflow%20-%202D%20CNN%20CIFAC10%20Image%20Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensorflow - 2D CNN CIFAC10 Image Classifier**"
      ],
      "metadata": {
        "id": "PgPyKVeA4XZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is CNN**\n",
        "\n",
        "A **Convolutional Neural Network (ConvNet/CNN)** is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics\n",
        "\n",
        "**Important Terms of CNN**\n",
        "\n",
        "- Convolutional Layer\n",
        "- Activation Function\n",
        "- Filter Size (Each filter extract different part of the image)\n",
        "- Stride Size\n",
        "- Max pooling\n",
        "- Flattening and Dense LayerWhat is CNN\n"
      ],
      "metadata": {
        "id": "jlHm3AMa4bIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Data and Model Building**"
      ],
      "metadata": {
        "id": "sgBT0GeS4pf6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrvFJ2SE4OnK"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-gpu==2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend==0.17.0"
      ],
      "metadata": {
        "id": "LdM45O6b4riv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D, Dropout"
      ],
      "metadata": {
        "id": "zEPiCzpL4t_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "Wuvc7Z944vgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Hajr3M4v4v19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10"
      ],
      "metadata": {
        "id": "pZJpjqOh4w5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "JGqqWu3K4y6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_name = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]"
      ],
      "metadata": {
        "id": "XCe-xAic402X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.max()"
      ],
      "metadata": {
        "id": "K3v9-Tv-41x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since Neural Network understand the data between **0 to 1**. Brininging our data in the range **0 to 1**. To do this we will simply divide the given data with the maximum value.\n",
        "\n"
      ],
      "metadata": {
        "id": "eAZZy3s342H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/x_train.max()\n",
        "x_test = x_test/x_train.max()"
      ],
      "metadata": {
        "id": "DL_aKl6W46rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape\n",
        "\n",
        "# x_train gives (50000, 32, 32, 3) - 50000 data, 32 x 32 bits, height and width, 3 is rgb, color.\n",
        "# x_test gives (10000, 32, 32, 3) - 10000 data, 32 x 32 bits, height and width, 3 is rgb, color."
      ],
      "metadata": {
        "id": "4CI86Fes47wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[0].astype(\"uint8\")) "
      ],
      "metadata": {
        "id": "Q1zycFFo48sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "0s_TpBC249h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# Only first layer needs input size\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", input_shape=[32, 32, 3])) # Same keeps the original data padding\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=2, padding=\"valid\")) # Valid tries to reduce the dimension\n",
        "\n",
        "# Dropout helps to avid the overfitting of the mode. Here we are dropping 50% of the input at this layer.\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=128, activation=\"relu\"))\n",
        "\n",
        "#Output layer. Unit is the size of the different output. Here we have 10 different outcomes.\n",
        "model.add(Dense(units=10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "42doixzj4-0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "3mguOh0L5BEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile the Model**"
      ],
      "metadata": {
        "id": "rkOHP9lO5Jc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "metadata": {
        "id": "JUj_53lm5Lsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting the Model**"
      ],
      "metadata": {
        "id": "D9uyC0F25NMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=10, epochs=10, verbose=1, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "NKHNzB3I5OGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above training we can see the validation accuracy is lesser than the accuracy. This means our model is **overfitting**. Also, if the validation accuracy is higher than the accuracy its called **underfitting**.\n",
        "\n",
        "So lets look at the point where it started overfillting by plotting the graph."
      ],
      "metadata": {
        "id": "xHeXuzJw5PoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy values\n",
        "# sparse_categorical_accuracy vs val_sparse_categorical_accuracy\n",
        "epoch_range = range(1, 11) # No of Epochs used to train. 11 - 1 = 10\n",
        "plt.plot(epoch_range, history.history[\"sparse_categorical_accuracy\"])\n",
        "plt.plot(epoch_range, history.history[\"val_sparse_categorical_accuracy\"])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e84zee5s5TQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss values\n",
        "# Loss vs Val_Loss\n",
        "plt.plot(epoch_range, history.history[\"loss\"])\n",
        "plt.plot(epoch_range, history.history[\"val_loss\"])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NTOI_J4K5Vma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Confusion Matrix**"
      ],
      "metadata": {
        "id": "PlP-FJVE5Wji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "mei_vWO45XT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "cjDHE2m55Z4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(mat, figsize=(9, 9), class_names=classes_name, show_normed=True)"
      ],
      "metadata": {
        "id": "Y8YDkEkT5a7f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}